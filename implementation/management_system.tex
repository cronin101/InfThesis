\section{Management System}

\subsection{Converting between Ruby and C objects}
One important issue to overcome, when designing an library to accelerate Ruby processing, is the fact that the RubyVM stores all raw values within \emph{objects}, in a manner that is very different from C.

Internally, the RubyVM's C implementation references all objects as of type \verb|VALUE|. This value-type is a slight misnomer as it (usually) contains a pointer to an object structure.

There are several object structures used to represent raw data within the RubyVM. However they all fall into one of two categories:
\begin{itemize}
     \item \verb|RObject| for storing the state of any bespoke object. This includes storage of instance variables and a pointer to the corresponding class hierarchy for lookup of all methods defined.
     \item A specialised object representation, used to increase performance of heavily utilised object types. Examples include \verb|RString|, \verb|RFloat|, and \verb|RArray|.
\end{itemize}

The first member of both aforementioned structures is another structure called \verb|RBasic|. This contains meta-data about the object, such as what type it is. Therefore, it is possible to obtain the typing information of any object designated by a \verb|VALUE|, by examining the meta-data present in its first structure member.

Since integers are often heavily utilised within computer programs, and often short-lived, the standard RubyVM implementation avoids the creation of integer objects in order to improve performance.
Instead, it encodes the value of the first $2^{64 - 2}$ integers directly into the \verb|VALUE| `pointer', setting the final 2 bits as the flag \verb|0x01|.
It can be deduced that a pointer with an odd value is not pointing to a valid memory location, as is true for any pointer that does not align to the machine's word-length boundaries. In this case, a flag lookup table can be used in order to determine the correct typing information.

When dealing with tagged-pointers, the corresponding value of pointer \verb|p| can be retrieved with \verb|p >> 1|. To create a tagged-pointer, the value \verb|x| can be encoded with \verb?(x << 1) | 0x01 ?. The RubiCL project exploits this fact by transferring an array of \verb|VALUE| pointers directly to the compute-device, whenever annotation has suggested that all contained elements are of \verb|Fixnum| type. There, the bit-shifting conversions, present at either end of the computation pipeline, can be performed in parallel in order to increase throughput.

\subsection{Transferring data to and from the compute-device}
As \ac{OpenCL} is designed to provide an abstraction over specific hardware details, the memory management functionality it provides reflects this agnosticism.
A common method for providing input data to a compute-device is to explicitly create a buffer of the required size, within the device's \emph{context}, and then enqueue a \verb|WriteBuffer| task to fill it with any elements to process. This buffer object is then provided as a kernel parameter, prior to kernel invocation. To retrieve the processed elements, a \verb|ReadBuffer| task is enqueued.

This workflow causes several issues. Firstly, when the compute-device selected is the system \ac{CPU}, unnecessary data copying occurs. The original location of the dataset is already addressable by the \ac{CPU} device so there is no need to move elements into a new buffer, this just causes unnecessary delay. The same is true when retrieving processed elements, there is no reason that the host program cannot access the element buffer directly. Secondly, when writing data into the device buffer, data-flow occurs through the host device. This is inefficient on many systems when interfacing with a \ac{GPU} device, since \emph{kernel-mode} execution is required to transfer data over the \ac{PCI} bus and \ac{OS}-enforced context switching increases latency.

Luckily, the \ac{OpenCL} \ac{API} provides a solution that is better-suited to the project's data transfer needs.
\emph{Pinned} buffers can be created by specifying the \verb|USE_HOST_PTR| flag and providing a pointer to the dataset residing within host memory.
When a dataset is pinned, the returned buffer object now merely references the original data location, yet can still be provided as a kernel parameter.
Upon providing a pinned buffer parameter, behaviour of the \ac{OpenCL} execution environment is dependent on the target device.
When the kernel is scheduled for execution on the \ac{CPU}, no memory transfer occurs and the original data can be accessed through the reference provided within a pinned buffer.
When the kernel is scheduled for execution on an external device, such as a \ac{GPU}, \ac{DMA} transfer of the dataset occurs and the elements are placed in device-local memory.
Before the host program can access the results of kernel execution, the pinned buffer must be \emph{unmapped}. At this point is it now guaranteed that the host memory state will reflect the finishing state of compute-device computation.

By utilising pinned memory, the RubiCL library avoids any unnecessary copying of data when executing on \ac{CPU} compute-devices. In addition, \ac{GPU} latency is reduced as \ac{DMA} transfer of the required dataset does not cause the \ac{OS} to invoke costly context-switching.

\subsection{Function parser}
The system's function parser is responsible for converting a supplied anonymous function into C syntax. The functionality of the parser is demonstrated in Listing~\ref{lst:parser_ex}
\begin{lstlisting}[
  language=Ruby,
  label=lst:parser_ex,
  caption=The \emph{LambdaBytecodeParser} converts an anonymous function Ruby object into an array of C expressions.
]
foo = 3
a_function = ->(x){ foo * (2 + x) }
#=> #<Proc:0x007f976207ff48@(pry):12 (lambda)>

parser = RubiCL::LambdaBytecodeParser.new(a_function)
#=> #<struct RubiCL::LambdaBytecodeParser
#   function=#<Proc:0x007f9761c362c0@(pry):15 (lambda)>>

parser.bytecode
#=> " == disasm: <RubyVM::InstructionSequence:block in __pry__
# == catch table
# | catch type: redo   st: 0000 ed: 0016 sp: 0000 cont: 0000
# | catch type: next   st: 0000 ed: 0016 sp: 0000 cont: 0016
# |-----------------------------------------------------------
# local table (size: 2, argc: 1 [opts: 0, rest: -1, post: 0,
#                                  block: -1, keyword: 0@3] s3)
#   [ 2] x<Arg>     
#   0000 trace            256                            (  22)
#   0002 trace            1
#   0004 getlocal         foo, 2
#   0007 trace            1
#   0009 putobject        2
#   0011 getlocal_OP__WC__0 2
#   0013 opt_plus         <callinfo!mid:+, argc:1, ARGS_SKIP>
#   0015 opt_mult         <callinfo!mid:*, argc:1, ARGS_SKIP>
#   0017 trace            512
#   0019 leave"
parser.parsed_operations
#=> [3, 2, "x", "+", "*"]

parser.to_infix
#=> ["3 * (2 + x)"]
\end{lstlisting}

The conversion process occurs over three stages: dumping bytecode, lexing, and reconstruction.

\paragraph*{Obtaining function bytecode}
The bytecode instructions, produced by a compiled anonymous function object, are provided by the \verb|RubyVM::InstructionSequence| module's \verb|disassemble| method.
It returns a human readable string that includes all stack-machine instructions.

\paragraph*{Lexing bytecode string}
Instructions of interest are extracted from the human-readable string. This is achieved via a regular expression containing a whitelist of keywords:
\begin{verbatim}
/(?:\d*\s*(?:(getlocal.*|putobject.*|opt_.*|branch.*).?))/
\end{verbatim}

The instructions are then tokenised, by the process detailed in Listing~\ref{lst:tokeniser_rules}.
The end result is a list of tokens representing stack-machine instructions, in \ac{RPN}.

The heavy reliance on regular expressions to parse bytecode is inelegant and fragile.
However, with access only to a human-readable string, and a lack of any formal grammar, it was the best tool at hand to get the job done.

\begin{lstlisting}[
  language=Ruby,
  label=lst:tokeniser_rules,
  caption=Tokenisation rules for lexing human-readable bytecode.
]
def translate(operation)
  case operation
  # First function argument
  when /getlocal_OP__WC__0 #{function.arity + 1}/
    'x'
  # Second function argument
  when /getlocal_OP__WC__0 #{function.arity}/
    'y'
  # Indexed bound variable
  when /getlocal_OP__WC__1 \d+/
    id = /WC__1 (?<i>\d+)/.match(operation)[:i].to_i
    index = locals_table.length - (id - 1)
    beta_reduction locals_table[index]
  # Named bound variable
  when /getlocal\s+\w+,\s\d+/
    name = /getlocal\s+(?<name>\w+),/.match(operation)[:name].to_sym
    beta_reduction name
  # Literal Zero
  when /putobject_OP_INT2FIX_O_0_C_/
    0
  # Literal One
  when /putobject_OP_INT2FIX_O_1_C_/
    1
  # Floating-Point Literal
  when /putobject\s+-?\d+\.\d+/
    operation.split(' ').last.to_f
  # Integer Literal
  when /putobject\s+-?\d+/
    operation.split(' ').last.to_i
  # Method Sending
  when /opt_send_simple/
    /mid:(?<method>.*?),/.match(operation)[:method].to_sym
  # Conditionals
  when /branch/
    LOOKUP_TABLE.fetch operation[/branch\w+/].to_sym
  # Built-in Operator
  when /opt_/
    LOOKUP_TABLE.fetch operation[/opt_\w+/].to_sym
  else
    raise "Could not parse: #{operation} in #{bytecode}"
  end
end

def beta_reduction variable_name
  function.binding.local_variable_get variable_name
end
\end{lstlisting}

\paragraph*{Expression reconstruction}

\begin{algorithm}[h]
  \caption{\ac{RPN} to infix expression conversion.}
  \label{alg:to_infix}

  \begin{algorithmic}
    \Function{RpnToInfix}{$tokens$}
    \State{$Stack \Leftarrow$ \verb|[ ]|}
    \While{\Call{length}{$tokens$} $ > 0$}
    \State{$token \Leftarrow $\Call{shift}{$tokens$}}
    \If{\Call{isLiteral}{$token$}}
    \State{\Call{push}{$Stack, token$}}
    \Else
    \State{$right \Leftarrow $\Call{pop}{$Stack$}}
    \State{$left \Leftarrow $\Call{pop}{$Stack$}}
    \State{$combined \Leftarrow $\Call{combine}{$token, left, right$}}
    \State{\Call{push}{$Stack, combined$}}
    \EndIf
    \EndWhile
    \EndFunction
  \end{algorithmic}
\end{algorithm}

The final stage of the translation process. It requires converting \ac{RPN} to infix form.
There is a well-defined algorithm for doing so, provided in Algorithm~\ref{alg:to_infix}.

The conversion algorithm makes the assumption that all non-literals are functions with arity 2. This is justified since it covers all mathematical operators required by the library. Outliers include unary negation and method sending operations. These are detected and handled by an additional level of logic, omitted from the basic algorithm for brevity.

\paragraph*{Handling conditionals}
Conditional operators, such as \verb|&&|, complicate the reconstruction process. Instead of modifying the value of a stack-machine, they may perform a branch. Whether or not this occurs depends on the \emph{truthyness} of the current value. This is caused by the optimisation of short-circuiting boolean calculations.

Luckily, at the point that the branch is possibly triggered, no further operators can mutate the previous value directly. This means that the difficultly of handling branching can be sidestepped by simply abandoning the current expression ending in a conditional, and starting a new stack. All expressions produced are then just combined in order after the token stream has been exhausted.

\subsection{Task queue}
The \verb|TaskQueue| management system buffers all deferred tasks, scheduled during the computation pipeline. It is responsible for detecting potential optimisations and applying them prior to dispatch.
By fusing compatible tasks, the number of passes over the data required can be reduced. The rules utilised to select and process tasks eligible for fusion are detailed in Listing~\ref{lst:fusion_rules}.

In the order presented, the types of fusion supported are as follows:
\begin{description}
\item[Map-map fusion] Adjacent \verb|map| tasks can be replaced by a single task that performs the side-effects of both tasks combined.

\item[Filter-filter fusion] Adjacent \verb|filter| tasks can be replaced by a single task that only retains elements passing both predicates.

\item[Map-filter fusion] A \verb|filter| task following a \verb|map| task can replace it, performing its mutation before generating presence flags. Filter tasks that have gained the additional responsibility to mutate are hereafter referred to as \verb|mapfilter| tasks.

\item[Filter-map fusion] Similarly, a \verb|map| task following a \verb|filter| task should not necessarily be scheduled. The side-effects of the \verb|map| can be performed after filtering by a fused \verb|mapfilter| kernel. This has the disadvantage that branching in the following map task, to avoid unnecessary calculation on items that won't be kept, will cause inefficient stalling in execution. However, if enough work-units are scheduled, the \ac{OpenCL} runtime can identify non-stalled units to swap-in. Nonetheless, time wasted by stalls in a fused kernel is insignificant compared to the time to schedule a new kernel and pass over the data again in a separate \verb|map| task.

\item[Map-mapfilter fusion] No different to \verb|map-filter| fusion. The side-effects of the replaced \verb|map| task are prepended to the \verb|mapfilter|'s preprocessing actions.

\item[Mapfilter-map fusion] Again, advantageous as it avoids scheduling another pass over the data. The side-effects of the unnecessary \verb|map| are appended to the \verb|mapfilter|'s post-processing actions.

\item[Mapfilter-filter fusion] In \verb|mapfilter| tasks that have no post-processing actions, the \verb|filter| segment can be updated in the same manner as when undergoing \verb|filter-filter| fusion.
\end{description}

\begin{lstlisting}[
  language=Ruby,
  label=lst:fusion_rules,
  caption=Fusion rules for combining tasks within the \emph{TaskQueue}.
]
@tasks = @tasks.reduce [] do |queue, task|
  if (*fixed_queue, previous = queue).empty? then [task]
  else
    case [previous.class, task.class]
    when ([RubiCL::Map] * 2), ([RubiCL::Filter] * 2)
      fixed_queue << previous.fuse!(task)

    when [RubiCL::Map, RubiCL::Filter]
      fixed_queue << RubiCL::MappingFilter.new(
          pre_map: previous, filter: task)

    when [RubiCL::Filter, RubiCL::Map]
      fixed_queue << RubiCL::MappingFilter.new(
          filter: previous, post_map: task)

    when [RubiCL::Map, RubiCL::MappingFilter]
      fixed_queue << task.pre_fuse!(previous)

    when [RubiCL::MappingFilter, RubiCL::Map]
      fixed_queue << previous.post_fuse!(task)

    when [RubiCL::MappingFilter, RubiCL::Filter]
      if previous.has_post_map?
        fixed_queue << previous << task
      else
        fixed_queue << previous.filter_fuse!(task)
      end
    else
      fixed_queue << previous << task
    end
  end
end
\end{lstlisting}

Options to turn-off \verb|TaskQueue| optimisation were introduced so that the magnitude of benefits can be studied.
